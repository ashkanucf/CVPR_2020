{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import bayesiancoresets as bc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from pygcn.utils import accuracy, load_data, normalize, normalize_adj\n",
    "from pygcn.models import GCN\n",
    "\n",
    "import matlab\n",
    "import matlab.engine\n",
    "\n",
    "class argument:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(A, K, algorithm):\n",
    "    alg = algorithm(A)\n",
    "    alg.run(K)\n",
    "    wts = alg.weights()\n",
    "    new_K = K\n",
    "    while len(wts.nonzero()[0]) < K:\n",
    "        new_K += K - len(wts.nonzero()[0])\n",
    "        alg.run(new_K)\n",
    "        wts = alg.weights()\n",
    "    return wts.nonzero()[0].tolist()\n",
    "\n",
    "def selection_SP(A, K):\n",
    "    eng = matlab.engine.start_matlab()\n",
    "    M_mat = matlab.double([K])\n",
    "\n",
    "    f_mat = matlab.double([A.numpy()[i].tolist() for i in range(A.size(0))])\n",
    "    s = eng.SP(eng.transpose(f_mat), M_mat)\n",
    "    ind = [int(ind) - 1 for ind in s[0]]\n",
    "\n",
    "    eng.quit()\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)\n",
    "    \n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    return loss_test.item(), acc_test.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, adj_flip, features, labels, idx_train, idx_val, idx_test = load_data(path=\"data/cora/\")\n",
    "adj_np = adj.to_dense().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models and test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argument()\n",
    "args.cuda = True\n",
    "args.fastmode = True\n",
    "args.epochs = 200\n",
    "args.lr = 1e-2\n",
    "args.weight_decay = 5e-4\n",
    "args.hidden = 16\n",
    "args.dropout = 0\n",
    "args.repeat = 100 # repeat this times to reduce randomness\n",
    "\n",
    "# x = np.linspace(10, 50, 5).astype(int)\n",
    "x = [20, 25, 30, 35, 40, 45, 50]\n",
    "\n",
    "accumulator = np.zeros((len(x), 4))\n",
    "\n",
    "for i, length in enumerate(x):\n",
    "    print(\"length:\", length)\n",
    "\n",
    "    # GIGA\n",
    "    idx_train = torch.LongTensor(selection(adj_np, length, bc.GIGA))\n",
    "    idx_test = torch.LongTensor(list(set(range(features.size(0))) - set(idx_train.numpy())))\n",
    "\n",
    "    for r in range(args.repeat):\n",
    "        model = GCN(nfeat=features.shape[1],\n",
    "                    nhid=args.hidden,\n",
    "                    nclass=labels.max().item() + 1,\n",
    "                    dropout=args.dropout)\n",
    "        optimizer = optim.Adam(model.parameters(),\n",
    "                               lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "        if args.cuda:\n",
    "            model.cuda()\n",
    "            features = features.cuda()\n",
    "            adj = adj.cuda()\n",
    "            labels = labels.cuda()\n",
    "            idx_train = idx_train.cuda()\n",
    "            idx_test = idx_test.cuda()\n",
    "\n",
    "        for epoch in range(args.epochs):\n",
    "            train(epoch)\n",
    "\n",
    "        accumulator[i, 0] += test()[1]\n",
    "    print('GIGA:', accumulator[i, 0] / args.repeat)\n",
    "\n",
    "    # FW\n",
    "    idx_train = torch.LongTensor(selection(adj_np, length, bc.FrankWolfe))\n",
    "    idx_test = torch.LongTensor(list(set(range(features.size(0))) - set(idx_train.numpy())))\n",
    "\n",
    "    for r in range(args.repeat):\n",
    "        model = GCN(nfeat=features.shape[1],\n",
    "                    nhid=args.hidden,\n",
    "                    nclass=labels.max().item() + 1,\n",
    "                    dropout=args.dropout)\n",
    "        optimizer = optim.Adam(model.parameters(),\n",
    "                               lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "        if args.cuda:\n",
    "            model.cuda()\n",
    "            features = features.cuda()\n",
    "            adj = adj.cuda()\n",
    "            labels = labels.cuda()\n",
    "            idx_train = idx_train.cuda()\n",
    "            idx_test = idx_test.cuda()\n",
    "\n",
    "        for epoch in range(args.epochs):\n",
    "            train(epoch)\n",
    "\n",
    "        accumulator[i, 1] += test()[1]\n",
    "    print('FW:', accumulator[i, 1] / args.repeat)\n",
    "\n",
    "    # KSP\n",
    "    idx_train = torch.LongTensor(selection_SP(adj_flip, length))\n",
    "    idx_test = torch.LongTensor(list(set(range(features.size(0))) - set(idx_train.numpy())))\n",
    "\n",
    "    for r in range(args.repeat):\n",
    "        model = GCN(nfeat=features.shape[1],\n",
    "                    nhid=args.hidden,\n",
    "                    nclass=labels.max().item() + 1,\n",
    "                    dropout=args.dropout)\n",
    "        optimizer = optim.Adam(model.parameters(),\n",
    "                               lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "        if args.cuda:\n",
    "            model.cuda()\n",
    "            features = features.cuda()\n",
    "            adj = adj.cuda()\n",
    "            labels = labels.cuda()\n",
    "            idx_train = idx_train.cuda()\n",
    "            idx_test = idx_test.cuda()\n",
    "\n",
    "        for epoch in range(args.epochs):\n",
    "            train(epoch)\n",
    "\n",
    "        accumulator[i, 2] += test()[1]\n",
    "    print('KSP:', accumulator[i, 2] / args.repeat)\n",
    "\n",
    "    # RND\n",
    "    for r in range(args.repeat):\n",
    "        idx_train = torch.LongTensor(np.random.choice(features.size(0), length))\n",
    "        idx_test = torch.LongTensor(list(set(range(features.size(0))) - set(idx_train.numpy())))\n",
    "\n",
    "        model = GCN(nfeat=features.shape[1],\n",
    "                    nhid=args.hidden,\n",
    "                    nclass=labels.max().item() + 1,\n",
    "                    dropout=args.dropout)\n",
    "        optimizer = optim.Adam(model.parameters(),\n",
    "                               lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "        if args.cuda:\n",
    "            model.cuda()\n",
    "            features = features.cuda()\n",
    "            adj = adj.cuda()\n",
    "            labels = labels.cuda()\n",
    "            idx_train = idx_train.cuda()\n",
    "            idx_test = idx_test.cuda()\n",
    "\n",
    "        for epoch in range(args.epochs):\n",
    "            train(epoch)\n",
    "\n",
    "        accumulator[i, -1] += test()[1]\n",
    "    print('RND:', accumulator[i, -1] / args.repeat)\n",
    "    print(\"\")\n",
    "accumulator /= args.repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "tfont = {'fontname':'Liberation Serif'}\n",
    "plt.plot(x, [a for a in accumulator[:, 2]], \"-*\", label=\"KSP\", linewidth=2, color=\"k\")\n",
    "plt.plot(x, [a for a in accumulator[:, 0]], \"-*\", label=\"GIGA\", linewidth=2)\n",
    "plt.plot(x, [a for a in accumulator[:, 1]], \"-*\", label=\"FW\", linewidth=2)\n",
    "plt.plot(x, [a for a in accumulator[:, 3]], \"-*\", label=\"RND\", linewidth=2, color='tab:red')\n",
    "plt.legend(prop=font_manager.FontProperties(family='Liberation Serif', size=13))\n",
    "plt.xlabel(\"Number of Selected Points\", size=14, **tfont)\n",
    "plt.ylabel(\"Test Accuracy\", size=14, **tfont)\n",
    "plt.xticks([20, 25, 30, 35, 40, 45, 50], size=14, **tfont)\n",
    "plt.yticks(size=14, **tfont)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
